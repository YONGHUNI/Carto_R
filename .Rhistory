res_foreach <- foreach(i=1:length(dset_c5),
#.combine = dplyr::bind_rows,
.packages = c("base")
) %dopar% {
#body of function goes here
stats::glm(dset$crim ~. , family = stats::poisson(link = "log"), data = dset_c5[[i]]) |>
# workaround by smuggling converted json strings from class glm
jsonlite::serializeJSON( pretty=T, digits=6L)|>
jsonlite::unserializeJSON()
}# end of foreach
# Always recommendable to stop the cluster when we are done working with it.
stopCluster(cl)
toc()
} # 14.02 sec elapsed
{ # <-  run here
tic()
# Making workers - Parallel Socket Cluster (https://www.blasbenito.com/post/02_parallelizing_loops_with_r/)
no_cores <- 8#detectCores(logical = F) - 1
cl <- makeCluster(no_cores, type="PSOCK")
# register working clusters
registerDoParallel(cl)
# parallel computation requires loop independence(independent to each loop)
# res[i] = res[i-1] + 1 not gonna work
# res[i] = x[i]+y[i] a proper example
# foreach function acts like a function. It saves the return value in the list.
# you can skip return(x) by calling function without assigning a variable
res_foreach <- foreach(i=1:length(dset_c5),
#.combine = dplyr::bind_rows,
.packages = c("tibble","jsonlite","stats","base")) %dopar% {
#body of function goes here
glm(dset$crim ~. , family = poisson(link = "log"), data = dset_c5[[i]]) |>
# workaround by smuggling converted json strings from class glm
serializeJSON( pretty=T, digits=6L)|>
unserializeJSON()
}# end of foreach
# Always recommendable to stop the cluster when we are done working with it.
stopCluster(cl)
toc()
} # 14.02 sec elapsed
{ # <-  run here
tic()
# Making workers - Parallel Socket Cluster (https://www.blasbenito.com/post/02_parallelizing_loops_with_r/)
no_cores <- 8#detectCores(logical = F) - 1
cl <- makeCluster(no_cores, type="PSOCK")
# register working clusters
registerDoParallel(cl)
# parallel computation requires loop independence(independent to each loop)
# res[i] = res[i-1] + 1 not gonna work
# res[i] = x[i]+y[i] a proper example
# foreach function acts like a function. It saves the return value in the list.
# you can skip return(x) by calling function without assigning a variable
res_foreach <- foreach(i=1:length(dset_c5),
#.combine = dplyr::bind_rows,
.packages = c("tibble","jsonlite","stats","base")) %dopar% {
#body of function goes here
glm(dset$crim ~. , family = poisson(link = "log"), data = dset_c5[[i]]) |>
# workaround by smuggling converted json strings from class glm
serializeJSON( pretty=F, digits=8L)|>
unserializeJSON()
}# end of foreach
# Always recommendable to stop the cluster when we are done working with it.
stopCluster(cl)
toc()
} # 14.02 sec elapsed
res_foreach <- foreach(i=1:length(dset_c5),
#.combine = dplyr::bind_rows,
.packages = c("tibble","jsonlite","stats","base")) %dopar% {
#body of function goes here
glm(dset$crim ~. , family = poisson(link = "log"), data = dset_c5[[i]]) |>
# workaround by smuggling converted json strings from class glm
serializeJSON( pretty=F, digits=4L)|>
unserializeJSON()
}# end of foreach
{ # <-  run here
tic()
# Making workers - Parallel Socket Cluster (https://www.blasbenito.com/post/02_parallelizing_loops_with_r/)
no_cores <- 8#detectCores(logical = F) - 1
cl <- makeCluster(no_cores, type="PSOCK")
# register working clusters
registerDoParallel(cl)
# parallel computation requires loop independence(independent to each loop)
# res[i] = res[i-1] + 1 not gonna work
# res[i] = x[i]+y[i] a proper example
# foreach function acts like a function. It saves the return value in the list.
# you can skip return(x) by calling function without assigning a variable
res_foreach <- foreach(i=1:length(dset_c5),
#.combine = dplyr::bind_rows,
.packages = c("tibble","jsonlite","stats","base")) %dopar% {
#body of function goes here
glm(dset$crim ~. , family = poisson(link = "log"), data = dset_c5[[i]]) |>
# workaround by smuggling converted json strings from class glm
serializeJSON( pretty=F, digits=4L)|>
unserializeJSON()
}# end of foreach
# Always recommendable to stop the cluster when we are done working with it.
stopCluster(cl)
toc()
} # 14.02 sec elapsed
{ # <-  run here
tic()
# Making workers - Parallel Socket Cluster (https://www.blasbenito.com/post/02_parallelizing_loops_with_r/)
no_cores <- 6#detectCores(logical = F) - 1
cl <- makeCluster(no_cores, type="PSOCK")
# register working clusters
registerDoParallel(cl)
# parallel computation requires loop independence(independent to each loop)
# res[i] = res[i-1] + 1 not gonna work
# res[i] = x[i]+y[i] a proper example
# foreach function acts like a function. It saves the return value in the list.
# you can skip return(x) by calling function without assigning a variable
res_foreach <- foreach(i=1:length(dset_c5),
#.combine = dplyr::bind_rows,
.packages = c("tibble","jsonlite","stats","base")) %dopar% {
#body of function goes here
glm(dset$crim ~. , family = poisson(link = "log"), data = dset_c5[[i]]) |>
# workaround by smuggling converted json strings from class glm
serializeJSON( pretty=F, digits=3L)|>
unserializeJSON()
}# end of foreach
# Always recommendable to stop the cluster when we are done working with it.
stopCluster(cl)
toc()
} # 14.02 sec elapsed
{ # <-  run here
tic()
# Making workers - Parallel Socket Cluster (https://www.blasbenito.com/post/02_parallelizing_loops_with_r/)
no_cores <- 6#detectCores(logical = F) - 1
cl <- makeCluster(no_cores, type="PSOCK")
# register working clusters
registerDoParallel(cl)
# parallel computation requires loop independence(independent to each loop)
# res[i] = res[i-1] + 1 not gonna work
# res[i] = x[i]+y[i] a proper example
# foreach function acts like a function. It saves the return value in the list.
# you can skip return(x) by calling function without assigning a variable
res_foreach <- foreach(i=1:length(dset_c5),
#.combine = dplyr::bind_rows,
.packages = c("tibble","jsonlite","stats","base")) %dopar% {
#body of function goes here
glm(dset$crim ~. , family = poisson(link = "log"), data = dset_c5[[i]]) |>
# workaround by smuggling converted json strings from class glm
serializeJSON( pretty=F, digits=8L)|>
unserializeJSON()
}# end of foreach
# Always recommendable to stop the cluster when we are done working with it.
stopCluster(cl)
toc()
} # 14.02 sec elapsed
{ # <-  run here
tic()
res_forloop <- list()
for (i in 1:length(dset_c5)) {
res_forloop[[i]] <-  glm(dset$crim ~. , family = poisson(link = "log"), data = dset_c5[[i]])
}
toc()
} # 21.81 sec elapsed in our computing rig
# Computing Environment of Our Server
# Expand the below to see
#############################################
benchmarkme::get_r_version()
#$platform
#[1] "x86_64-w64-mingw32"
#$arch
#[1] "x86_64"
#$os
#[1] "mingw32"
#$crt
#[1] "ucrt"
#$system
#[1] "x86_64, mingw32"
#$status
#[1] ""
#$major
#[1] "4"
#$minor
#[1] "2.2"
#$year
#[1] "2022"
#$month
#[1] "10"
#$day
#[1] "31"
#$`svn rev`
#[1] "83211"
#$language
#[1] "R"
#$version.string
#[1] "R version 4.2.2 (2022-10-31 ucrt)"
#$nickname
#[1] "Innocent and Trusting"
benchmarkme::get_cpu()
#$vendor_id
#[1] "GenuineIntel"
#$model_name
#[1] "Intel(R) Xeon(R) W-1370 @ 2.90GHz"
#$no_of_cores
#[1] 16
benchmarkme::get_ram()
# 137 GB
#############################################
library(mlbench)
library(tidyverse)
data(BostonHousing)
dim(BostonHousing)
head(BostonHousing)
#import test dataset
dset <- BostonHousing
#The original data are 506 observations on 14 variables, medv being the target variable:
#crim	per capita crime rate by town
#zn	proportion of residential land zoned for lots over 25,000 sq.ft
#indus	proportion of non-retail business acres per town
#chas	Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)
#nox	nitric oxides concentration (parts per 10 million)
#rm	average number of rooms per dwelling
#age	proportion of owner-occupied units built prior to 1940
#dis	weighted distances to five Boston employment centres
#rad	index of accessibility to radial highways
#tax	full-value property-tax rate per USD 10,000
#ptratio	pupil-teacher ratio by town
# b     1000(B-0.63)^2 where B the proportion of blacks by town
#lstat	percentage of lower status of the population
#medv	median value of owner-occupied homes in USD 1000's
# 13C5 = 1287 combinations
# a list of variable combinations
dset_c5 <- combn(dset[,2:14],5,simplify=F)
# for benchmarks
library(tictoc)
# simple for loop - run at the curly bracket to benchmark
{ # <-  run here
tic()
res_forloop <- list()
for (i in 1:length(dset_c5)) {
res_forloop[[i]] <-  glm(dset$crim ~. , family = poisson(link = "log"), data = dset_c5[[i]])
}
toc()
} # 21.81 sec elapsed in our computing rig
# summary i-th model in the list
summary.glm(res_forloop[[i]])
# parallel foreach loop
# It seems that foreach loop function doesn't like lm/glm class
# Always falls into infinite loop, needs interrupt to stop
# So, I suggest following workaround
library(doParallel)
# https://www.blasbenito.com/post/02_parallelizing_loops_with_r/
library(jsonlite)
{ # <-  run here
tic()
# Making workers - Parallel Socket Cluster (https://www.blasbenito.com/post/02_parallelizing_loops_with_r/)
no_cores <- 6#detectCores(logical = F) - 1
cl <- makeCluster(no_cores, type="PSOCK")
# register working clusters
registerDoParallel(cl)
# parallel computation requires loop independence(independent to each loop)
# res[i] = res[i-1] + 1 not gonna work
# res[i] = x[i]+y[i] a proper example
# foreach function acts like a function. It saves the return value in the list.
# you can skip return(x) by calling function without assigning a variable
res_foreach <- foreach(i=1:length(dset_c5),
#.combine = dplyr::bind_rows,
.packages = c("tibble","jsonlite","stats","base")) %dopar% {
#body of function goes here
glm(dset$crim ~. , family = poisson(link = "log"), data = dset_c5[[i]]) |>
# workaround by smuggling converted json strings from class glm
serializeJSON( pretty=F, digits=8L)|>
unserializeJSON()
}# end of foreach
# Always recommendable to stop the cluster when we are done working with it.
stopCluster(cl)
toc()
} # 14.02 sec elapsed
# Some information was lost(e.g., Call: y~x) during conversion
## Call:
## structure(list(), names = character(0))
# should be
## glm(formula = dset$crim ~ ., family = poisson(link = "log"), data = dset_c5[[i]])
# But It's negligible
summary.glm(res_foreach[[i]])
## also you can access to the info about ?goodness of fit?(correct me if I was wrong)
res_foreach[[i]]$deviance
res_foreach[[i]]$null.deviance
res_foreach[[i]]$aic
# But It's negligible
summary(res_foreach[[i]])
cl <- makeCluster(no_cores, type="FORK")
cl <- makeCluster(no_cores, type="MPI")
install.packages("snow")
library(snow)
cl <- makeCluster(no_cores, type="MPI")
install.packages("Rmpi")
library(Rmpi)
cl <- makeCluster(no_cores, type="MPI")
library(Rmpi)
library(Rmpi)
detach("package:Rmpi", unload = TRUE)
install.packages("Rmpi")
library(Rmpi)
install.packages("Rmpi",type = "source")
remove.packages("Rmpi")
install.packages("Rmpi",type = "source")
install.packages("Rmpi")
library(Rmpi)
library(Rmpi)
library(tidyverse)
mtcars
mtcars -> test1
mtcars -> test2
bind_cols(test1,test2)
bind_cols(test1,test2) %>% names
cbind(test1,test2) %>% names
bind_cols(test1,test2,.name_repair = "unique" %>% names
)
bind_cols(test1,test2,.name_repair = "unique") %>% names
bind_cols(test1,test2,.name_repair = "minimal") %>% names
bind_cols(test1,test2,.name_repair = "universal") %>% names
setwd("C:/Users/dydgn/OneDrive - SNU/PMgapfilling/10_map&landcover/새 폴더/data/ddareungi")
# save as a file
ggsave(themap,
filename = "map.svg",
#dpi = 512,
scale = 2
)
# save as a file
ggsave(themap,
filename = "map.svg",
#dpi = 512,
scale = 2
)
csv2sf <- function(directory){
library(tidyverse)
library(sf)
readr::read_csv(directory,
locale = readr::locale(
'ko',
encoding = 'euc-kr'
),
skip = 4
)  -> tmp
names(tmp) <- c("st#", "name", "gu", "addr", "y", "x",
"startdate", "LCDbike", "QRbike", "runsON")
tmp %>%
filter_at(vars(x, y), all_vars(!is.na(.))) %>%
sf::st_as_sf(coords = c("x", "y"), #remove =F,
crs = 4326, agr = "constant")
}
xlsx2sf <- function(directory){
library(tidyverse)
library(sf)
readxl::read_xlsx(directory,skip = 4,col_names = F) -> tmp
names(tmp) <- c("st#", "name", "gu", "addr", "y", "x",
"startdate", "LCDbike", "QRbike", "runsON")
tmp %>%
filter_at(vars(x, y), all_vars(!is.na(.))) %>%
sf::st_as_sf(coords = c("x", "y"), #remove =F,
crs = 4326, agr = "constant")
}
library(tidyverse)
library(DescTools)
library(sf)
library(geojsonsf)
library(stars)
library(terra)
library(leafem)
library(tmaptools)
library(ggspatial)
#library(terrainr) caused rendering issue
# import and make Seoul adm boundary data
adm_seoul <-geojson_sf("https://raw.githubusercontent.com/vuski/admdongkor/master/ver20220701/HangJeongDong_ver20220701.geojson") %>%
st_make_valid() %>%
group_by(sidonm) %>%
summarise() %>%
filter(sidonm %like% "서울특별시")
# import Google map satellite imagery using WMS protocol
# 13: best zoom level for considering trade off between resolution and time
# (22.92 sec elapsed, approx. 20m spatial resolution)
# zoom level(fyi)
#0 - 19
#0 lowest zoom (whole world)
#19 highest zoom (individual buildings, if available)
rs_seoul <- read_osm(adm_seoul,
type = "https://mt1.google.com/vt/lyrs=s&hl=en&z={z}&x={x}&y={y}",
zoom = 13) %>% terra::rast()
# high performance raster re-projection
#%>%
#terra::project(crs(st_crs(32652)[[2]]),
#               threads = T)
# change projection for plotting(ggplot doesn't support)
adm_seoul <- st_transform(adm_seoul, st_crs(rs_seoul))
sfbike <- csv2sf("2021_jan_31.csv") %>% st_transform(st_crs(rs_seoul)) %>%
select(geometry) %>% mutate(`Legend` = "Ddareungi Stations")
# AQ stations
rawcatalog <- readxl::read_xlsx("./mStations_2017.xlsx",skip = 3) %>%
.[-1,]
# change korean col names
names(rawcatalog) <- c("region", "city","obs_code","obs_nm","addr","x","y","note")
# removing obsolete stations
for (i in 1:length(rawcatalog$city)) {
if (!is.na(rawcatalog$note[i])&&is.na(rawcatalog$obs_code[i])) {
rawcatalog$obs_code[i] <- rawcatalog$obs_code[i-1]
rawcatalog$obs_code[i-1] <- NA
}
}
# filtering out obsolete and non-Seoul stations
seoul_obs <- filter(rawcatalog,grepl('^11',obs_code))[c(3,5:7)] %>%
distinct(obs_code, .keep_all = T)  %>%
sf::st_as_sf(coords = c("x", "y"),# remove =F,
crs = 4326, agr = "constant")  %>%
st_transform(st_crs(rs_seoul)) %>%
select(geometry) %>%
mutate(`Legend` = "Air Quality Monitoring Stations")
# making data for point layer
points4plot <- bind_rows(seoul_obs,sfbike) %>%
mutate(`Legend`=as.factor(`Legend`) #%>% fct_rev
) %>%
# for making AQ stations as the top layer(render later)
arrange(desc(`Legend`)) #%>%
# if using geom_points...
#mutate(x = st_coordinates(.)[,1],
#       y = st_coordinates(.)[,2])
# convert to tibble for plotting stacked raster
rs_seoul %>%
terra::as.data.frame(xy=T) %>%
as_tibble() %>% rename(Red = red,
Green = green,
Blue = blue) -> tib_rseoul
# base ggplot frame
ggplot()+
# draw satellite raster
# equivalent to `terrainr::geom_spatial_rgb()` that causes a rendering issue
geom_raster(data = tib_rseoul,
aes(x = x, y =y),
fill = rgb(red = tib_rseoul$Red,
green = tib_rseoul$Green,
blue = tib_rseoul$Blue,
maxColorValue = 255)
)+
# draw sf points
ggplot2::geom_sf(data=points4plot,
#size = 1.5,
#shape = 21,
stroke = .7,
aes(col = Legend,
fill = Legend,
size = Legend,
shape = Legend
),
na.rm=T
)+
# Change fill & border color
# Red dots with yellow outline for bike stations,
# Blue with light cyan outline for air quality monitoring stations
scale_color_manual(values = c("Air Quality Monitoring Stations" = "navy",
"Ddareungi Stations" = "yellow")
)+
scale_fill_manual(values = c("Air Quality Monitoring Stations" = "cyan",
"Ddareungi Stations" = "red")
) +
scale_size_manual(values = c("Air Quality Monitoring Stations" = 4,
"Ddareungi Stations" = 2.5)
) +
scale_shape_manual(values = c("Air Quality Monitoring Stations" = 24,
"Ddareungi Stations" = 21)
)+
# Fix aspect ratio
coord_fixed()+
# aes for scalebar
annotation_scale(location = "br", width_hint = 0.3,
line_col ="white", text_col = "white", text_cex = 1.3,
pad_x = unit(.07, "npc"), pad_y = unit(.07, "npc")) +
# aes for north arrow
annotation_north_arrow(location = "bl", which_north = "true",
pad_x = unit(.87, "npc"), pad_y = unit(.83, "npc"),
style = north_arrow_minimal(
line_width = 4, text_size = 26,
line_col = "white", text_col = "white"
)) +
# display tic labels as lon,lat
ggplot2::coord_sf(datum=st_crs(4326))+
xlab("Longitude") + ylab("Latitude") +
# you can add a title as well as a subtitle
#ggtitle("Title", subtitle = "Subtitle") +
# theme setttings
theme_minimal()+
# fine tune for a legned
theme(
# I also want to put the legend inside the map
legend.position = c(0.05, 0.05),
legend.justification = c("left", "bottom"),
legend.background = element_rect(fill = 'white'),
# Please remove the axis and labels (i.e., Latitude and Longitude
# both the number
axis.text.x=element_blank(),
axis.text.y=element_blank(),
# and labels
axis.title.x=element_blank(),
axis.title.y=element_blank(),
# and background grids
panel.grid.minor = element_blank(),
panel.grid.major = element_blank()
) -> themap #save as a variable
themap # a quick look
# save as a file
ggsave(themap,
filename = "map.svg",
#dpi = 512,
scale = 2
)
rs_seoul <- read_osm(adm_seoul,
type = "https://mt1.google.com/vt/lyrs=s&hl=en&z={z}&x={x}&y={y}",
zoom = 15) %>% terra::rast()
rs_seoul
terra::writeRaster("./data/rast_seoul.tiff")
terra::writeRaster(rs_seoul,"./data/rast_seoul.tiff")
